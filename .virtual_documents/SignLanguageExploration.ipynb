import tensorflow as tf
import mediapipe as mp
import cv2
import pandas as pd
import numpy as np


while cap.isOpened():
    _,frame = cap.read()
    frame=cv2.flip(frame,1)
    cv2.imshow('gody',frame)
    if cv2.waitKey(10) & 0xFF == ord('q'): 
        break
cap.release()
cv2.destroyAllWindows()


84/4


landmarks=['class']
for i in range(1,22):
    landmarks += ['x{}'.format(i),'y{}'.format(i),'z{}'.format(i),'v{}'.format(i)]

print(len(landmarks))
work=pd.DataFrame(columns=landmarks)


mp_hands=mp.solutions.hands
mp_draw=mp.solutions.drawing_utils
mp_drawing_style=mp.solutions.drawing_styles
cap = cv2.VideoCapture(0)


index=0
img_count = 0
frames_count = 0
alphabet =['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']
with mp_hands.Hands() as hand:
    while cap.isOpened():
        _, frame = cap.read()
        frame = cv2.flip(frame, 1)
        frame.flags.writeable = False
        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB )
        results = hand.process(frame)
        frame.flags.writeable = True
        
        if results.multi_hand_landmarks:
            for hand_landmark in results.multi_hand_landmarks:
                mp_draw.draw_landmarks(frame,hand_landmark,mp_hands.HAND_CONNECTIONS,
                        mp_drawing_style.get_default_hand_landmarks_style(),
                       mp_drawing_style.get_default_hand_connections_style())
            
            hands = results.multi_hand_landmarks[0].landmark
            frames_count += 1
            if frames_count % 5 == 0:
                img_count += 1
                hand_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in hands]).flatten())
                hand_row.insert(0,alphabet[index])
                added=pd.DataFrame([hand_row],columns=landmarks)
                work=pd.concat([work,added])
            
        Text = alphabet[index] +' Images: ' + str(img_count)
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        frame = cv2.putText(frame,Text,(50,80), cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),4)
        cv2.imshow('Window',frame)
        n = cv2.waitKey(1) & 0xFF == ord('n')
        b = cv2.waitKey(1) &0xFF == ord('b')
        q = cv2.waitKey(1) & 0xFF == ord('q')
        if n: 
            if index != 25:
                index += 1
                img_count = 0
        if b: 
            if index != 0:
                index -= 1
            
        if q: 
            break
cap.release()
cv2.destroyAllWindows()


work.to_csv('hand_letters.csv',index=False)


cap.release()
cv2.destroyAllWindows()


from sklearn.ensemble import RandomForestClassifier as RFC


model =RFC(verbose=2)


data = pd.read_csv('hand_letters.csv')


target = data.pop('class')


model.fit(data,target)


from sklearn.model_selection import cross_val_score as cvs


score = cvs(model,data,target,cv=5,verbose=2)


score


mp_hands=mp.solutions.hands
mp_draw=mp.solutions.drawing_utils
mp_drawing_style=mp.solutions.drawing_styles
cap = cv2.VideoCapture(0)


index=0
img_count = 0
frames_count = 0
text = ''
letter = ''
alphabet =['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']
with mp_hands.Hands() as hand:
    while cap.isOpened():
        _, frame = cap.read()
        frame = cv2.flip(frame, 1)
        frame.flags.writeable = False
        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB )
        results = hand.process(frame)
        frame.flags.writeable = True
        
        if results.multi_hand_landmarks:
            for hand_landmark in results.multi_hand_landmarks:
                mp_draw.draw_landmarks(frame,hand_landmark,mp_hands.HAND_CONNECTIONS,
                        mp_drawing_style.get_default_hand_landmarks_style(),
                       mp_drawing_style.get_default_hand_connections_style())
            
            hands = results.multi_hand_landmarks[0].landmark
            
            hand_row=list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in hands]).flatten())
            prediction = model.predict([hand_row])
            letter = prediction[0]
       
                
            
        text += letter
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        frame = cv2.putText(frame,text,(50,80), cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),4)
        cv2.imshow('Window',frame)
        n = cv2.waitKey(1) & 0xFF == ord('n')
        b = cv2.waitKey(1) &0xFF == ord('b')
        q = cv2.waitKey(1) & 0xFF == ord('q')
        if n: 
            if index != 25:
                index += 1
                img_count = 0
        if b: 
            if index != 0:
                index -= 1
            
        if q: 
            break
cap.release()
cv2.destroyAllWindows()
